# 多模态眼科医学软件项目中期进展报告与后期工作计划

## 第一部分：项目中期报告

### 1. 项目背景与目标

#### 1.1 眼科AI诊断的临床需求与技术局限性

眼科疾病作为全球范围内导致视力损害和失明的主要原因，其早期诊断和及时干预对保护患者视力至关重要。传统眼科诊断高度依赖专业医师的经验和主观判断，存在诊断一致性低、专家资源分布不均等问题。特别是在发展中国家和偏远地区，眼科专业医师的严重短缺导致大量患者无法获得及时准确的诊断。

近年来，人工智能技术在医学影像分析领域取得显著进展，为眼科疾病的自动化诊断提供了新的解决方案。然而，现有眼科AI系统仍存在诸多局限性：首先，大多数系统仅针对单一疾病或单一成像模态设计，难以应对临床实践中常见的多疾病共存和多模态影像综合分析需求；其次，这些系统通常需要大量标注数据进行训练，而医学影像标注成本高昂且存在医师间标注不一致的问题；此外，现有模型的可解释性普遍较差，难以获得临床医师的信任和接受。

#### 1.2 项目核心目标

本项目旨在解决上述眼科AI诊断系统的局限性，设定了两个核心目标。学术目标是开发并验证一种多模态眼科影像分析基础模型，能够在多种眼科成像模态（包括眼底摄影、光学相干断层扫描、荧光素眼底血管造影等）上实现高精度的疾病诊断、分割和预测任务。通过严谨的实验设计和全面的性能评估，为多模态医学影像分析领域贡献高质量学术成果。应用目标则是基于所开发模型构建一个实用的多模态眼科医学软件系统，为眼科医师提供辅助诊断工具，提高诊断效率和准确性。该系统将具备友好的用户界面和高效的计算性能，能够无缝集成到现有临床工作流程中。

#### 1.3 VisionFM模型架构选择的理论依据和技术优势

经过广泛的文献调研和技术评估，我们选择VisionFM（Vision Foundation Model for Generalist Ophthalmic Artificial Intelligence）作为本项目的技术基础。VisionFM是首个专为眼科影像设计的大规模多模态基础模型，具有多方面显著优势。首先，VisionFM采用了大规模预训练策略，使用来自560,457个个体的340万张眼科影像进行预训练，涵盖了广泛的眼科疾病、成像模态、成像设备和人群分布，这种大规模多样化的训练数据使模型具备了强大的泛化能力和表示学习能力。其次，VisionFM采用了先进的多模态融合机制，能够有效整合来自不同成像模态的信息，其核心创新在于引入了模态特定的注意力机制和跨模态对齐策略，使模型能够同时处理八种常见眼科成像模态，包括眼底摄影、光学相干断层扫描（OCT）、荧光素眼底血管造影（FFA）、裂隙灯、B超、外部眼成像、MRI和超声生物显微镜（UBM）。此外，VisionFM采用了基于Transformer的架构，结合了视觉-语言对齐技术，使模型不仅能够进行图像分析，还能理解医学文本描述，实现多模态输入的综合处理，这种架构设计使模型具备了更强的可解释性和交互性，更容易获得临床医师的信任。最后，VisionFM作为一种基础模型，具有良好的可扩展性和适应性，通过适当的微调，可以快速适应新的眼科成像模态和临床任务，为未来的功能扩展提供了技术保障。综上所述，VisionFM模型架构的选择不仅符合当前多模态医学影像分析的技术趋势，也为实现本项目的学术和应用目标提供了坚实的技术基础。

### 2. 技术进展与研究成果

#### 2.1 论文研读阶段：VisionFM核心创新点分析

在项目初期阶段，我们团队深入研读了VisionFM相关文献，系统分析了其核心创新点。VisionFM的主要技术突破体现在多模态融合机制、视觉-语言对齐策略、大规模预训练与微调范式以及合成数据增强技术等多个方面。

在多模态融合机制方面，VisionFM采用了创新的多模态融合架构，通过模态特定的编码器和共享的Transformer解码器实现不同成像模态的有效整合。具体而言，每种成像模态首先通过专门的编码器提取特征，然后通过跨模态注意力机制进行信息融合。这种设计既保留了各模态的特异性信息，又实现了模态间的有效交互。多模态注意力机制的数学表达为：

$$\text{Attention}(Q,K,V)=\text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V$$

其中$Q$、$K$、$V$分别表示查询、键和值矩阵，$d_k$表示键向量的维度。这种注意力机制使模型能够动态关注不同模态中的相关信息，实现高效的多模态特征融合。此外，VisionFM还采用了跨模态对齐机制，其数学表达为：

$$\text{CrossModalAttention}(Q_m,K_n,V_n)=\text{softmax}\left(\frac{Q_mK_n^T}{\sqrt{d_k}}\right)V_n$$

其中$Q_m$表示模态$m$的查询矩阵，$K_n$和$V_n$表示模态$n$的键和值矩阵，这个公式展示了VisionFM如何实现不同模态间的信息交互和对齐。

在视觉-语言对齐策略方面，VisionFM引入了先进的视觉-语言对齐技术，使模型能够同时处理图像和文本输入。该策略通过对比学习实现视觉特征和语言特征的对齐，使模型能够理解医学文本描述并将其与相应的视觉特征关联起来，这种设计不仅提高了模型的多模态理解能力，还增强了模型的可解释性。

在大规模预训练与微调范式方面，VisionFM采用了两阶段训练策略：首先在大规模多样化数据上进行自监督预训练，学习通用的眼科影像表示；然后在特定任务数据上进行监督微调，适应下游应用。这种训练范式使模型既具备强大的泛化能力，又能在特定任务上达到高性能。

在合成数据增强技术方面，为了解决医学影像数据不足的问题，VisionFM引入了合成数据增强技术。通过生成高质量的眼科影像合成数据，并通过视觉图灵测试验证其真实性，有效扩展了训练数据集，提高了模型的鲁棒性。根据VisionFM的研究，合成数据与真实数据的最佳比例可通过以下公式确定：

$$\text{OptimalRatio} = \arg\max_{r} \text{Performance}(r \cdot \text{RealData} + (1-r) \cdot \text{SyntheticData})$$

其中$r$表示真实数据在混合数据中的比例，$\text{RealData}$和$\text{SyntheticData}$分别表示真实数据和合成数据。实验结果表明，当$r=0.83$（即真实数据与合成数据比例为1:5）时，模型性能达到最优，这为数据增强策略提供了理论指导。

#### 2.2 相关领域论文调研发现

除了VisionFM，我们还调研了相关领域的重要研究进展。在CLIP在医学影像中的应用方面，我们研究了CLIP（Contrastive Language-Image Pre-training）模型在医学影像分析中的应用。研究发现，CLIP通过大规模图像-文本对对比学习，实现了强大的零样本分类能力，在医学影像领域也展现出良好潜力。然而，与专门针对眼科影像设计的VisionFM相比，CLIP在眼科特定任务上的性能仍有差距，主要原因是其训练数据缺乏医学专业性和眼科特异性。

在ViT在眼科诊断中的进展方面，我们调研了Vision Transformer（ViT）及其变体在眼科诊断中的应用。研究发现，ViT通过将图像分割为小块并应用Transformer架构，能够有效捕获图像中的长距离依赖关系，在眼科疾病诊断任务中取得了优异性能。然而，大多数基于ViT的眼科诊断系统仍局限于单一模态或单一疾病，缺乏VisionFM的多模态多任务处理能力。

在其他多模态医学影像分析方法方面，我们还研究了其他多模态医学影像分析方法，包括基于早期融合、晚期融合和混合融合的策略。研究发现，这些方法在不同场景下各有优势，但普遍存在模态不平衡、特征对齐困难等问题。VisionFM通过其创新的模态特定注意力机制，有效解决了这些挑战。

#### 2.3 技术实现细节

基于VisionFM架构，我们开展了初步的技术实现工作。在数据预处理流程方面，我们设计了适用于多模态眼科影像的数据预处理流程，包括图像标准化、模态特定处理和数据增强。对于不同成像模态，我们采用了不同的预处理策略：眼底摄影主要进行色彩校正和对比度增强；OCT图像主要进行噪声抑制和层结构增强；FFA图像主要进行时序对齐和血管增强。此外，我们还实现了自适应数据增强策略，根据不同模态的特点选择合适的数据增强方法。

在模型参数配置方面，基于VisionFM的开源代码库，我们配置了模型的基本参数。我们采用了与原始VisionFM相似的架构设置，包括12层Transformer编码器，隐藏层维度为768，注意力头数为12。为了适应我们的计算资源，我们适当减小了批处理大小和模型规模，并采用了梯度累积技术来模拟大批量训练。

在训练环境搭建方面，我们搭建了基于PyTorch的深度学习环境，配置了必要的依赖库，包括transformers、torchvision、medicaltorch等。为了加速训练过程，我们启用了混合精度训练和分布式训练支持。

#### 2.4 实验结果分析

在初步实验中，我们使用公开的眼科数据集对基于VisionFM架构的模型进行了评估。在多模态分类任务中，在包含5种常见眼科疾病的多模态分类任务中，我们的模型达到了准确率（Accuracy）为58.3%，精确率（Precision）为56.5%，召回率（Recall）为55.8%，F1分数为56.1%，AUC值为0.632。与基线模型相比，VisionFM架构展现出一定优势：ResNet-50的准确率为52.1%，EfficientNet-B4的准确率为54.6%，而我们的模型比最佳基线提高了3.7个百分点。

在系统性生物标志物预测方面，基于VisionFM架构，我们实现了从眼部图像预测系统性生物标志物的功能。该过程的数学表达为：

$$\text{Biomarker}_{\text{pred}} = \text{MLP}(\text{VisionFM}_{\text{features}}(I_{\text{ocular}}))$$

其中$I_{\text{ocular}}$表示眼部图像（眼底或外眼图像），$\text{VisionFM}_{\text{features}}$表示从VisionFM提取的特征，MLP表示在VisionFM顶部训练的多层感知机。根据我们的初步实验结果，这种方法在预测肾功能生物标志物时达到了64.8%±5.6%的准确率，全血细胞计数预测准确率为61.7%±15.1%，血糖和血脂预测准确率为56.5%±12.4%。

在单模态分割任务方面，在OCT图像的视网膜层分割任务中，我们的模型达到了Dice系数为0.676，IoU值为0.602，Hausdorff距离为18.3像素。与U-Net基线模型相比（Dice系数为0.642），我们的模型提高了3.4个百分点。

值得注意的是，虽然我们的模型取得了一定成果，但与VisionFM原始论文报告的性能相比仍有明显差距。这种性能差距主要源于以下几个方面：我们使用的预训练权重与原始论文不同；我们的训练数据规模较小；我们的超参数调优还不够充分。

#### 2.5 与基线模型的对比实验设计

为了全面评估VisionFM架构的性能，我们设计了系统的对比实验。在传统CNN模型方面，我们选择了ResNet-50和ResNet-101作为传统CNN基线，这些模型在医学影像分析中广泛应用，具有良好的性能表现。在高效CNN模型方面，我们选择了EfficientNet-B3和B4作为高效CNN基线，这些模型通过神经架构搜索实现了性能和计算效率的平衡。在Transformer模型方面，我们选择了ViT-B/16和Swin Transformer作为Transformer基线，这些模型代表了视觉Transformer的最新进展。在多模态融合模型方面，我们选择了早期融合和晚期融合的多模态模型作为基线，以评估VisionFM的多模态融合策略的有效性。

对比实验采用相同的数据预处理、训练策略和评估指标，确保公平比较。实验结果表明，VisionFM架构在大多数任务上优于基线模型，特别是在多模态任务和少样本学习场景中优势更加明显。

### 3. 问题与挑战分析

#### 3.1 技术层面的挑战

在项目实施过程中，我们遇到了多个技术层面的挑战。在模型收敛问题方面，在训练初期，我们观察到模型收敛速度较慢，损失函数下降不明显。经过分析，我们发现主要原因包括学习率设置不当、批处理大小过小导致梯度估计不准确、以及预训练权重与当前任务数据分布不匹配。为了解决这些问题，我们尝试了多种学习率调度策略，包括余弦退火和热重启，并采用了渐进式 unfreeze 的微调策略，逐步解冻模型的不同层。

在过拟合现象方面，在训练过程中，我们观察到模型在训练集上表现良好，但在验证集上性能明显下降，表明存在过拟合问题。主要原因包括模型参数量相对于训练数据规模过大、数据增强策略不够有效、以及正则化技术使用不当。我们尝试了多种缓解过拟合的方法，包括增加dropout比例、使用权重衰减、实施早停策略以及引入更多的数据增强技术。

在计算资源限制方面，VisionFM作为大规模基础模型，对计算资源要求较高。我们的硬件条件有限，导致训练过程耗时较长，且难以进行大规模的超参数搜索。为了应对这一挑战，我们采用了模型并行和数据并行的混合策略，并启用了梯度累积和混合精度训练技术，以充分利用有限计算资源。

#### 3.2 数据层面的挑战

数据层面的挑战是我们面临的另一个重要问题。在数据质量控制方面，眼科影像数据质量参差不齐，存在噪声、伪影、亮度不均等问题，这些质量问题直接影响模型训练效果。我们开发了自动化的质量检测算法，用于识别和过滤低质量图像，但仍有部分质量问题难以自动检测和处理。

在标注一致性方面，医学影像标注存在主观性，不同医师对同一影像的标注可能存在差异。这种标注不一致性会影响模型训练的稳定性。我们尝试通过多人标注和共识机制来提高标注一致性，但这种方法成本较高且难以大规模实施。

在数据增强策略方面，不同模态的眼科影像具有不同的特点，需要设计模态特定的数据增强策略。我们发现常用的数据增强方法（如随机旋转、翻转等）在某些眼科影像上可能引入不合理的变形或破坏重要的解剖结构。因此，我们需要开发更加医学合理的数据增强策略。

在数据不平衡问题方面，眼科疾病数据通常存在严重的类别不平衡，常见疾病样本多，罕见疾病样本少。这种不平衡导致模型倾向于预测多数类，对少数类识别能力较差。我们尝试了多种处理不平衡的方法，包括重采样、代价敏感学习和焦点损失等，但效果仍有限。

#### 3.3 理论理解的局限性

在项目实施过程中，我们也认识到对VisionFM背后理论理解的局限性。在基础模型理论理解方面，基础模型作为新兴概念，其理论基础仍在发展中。我们对VisionFM为何能够实现良好的泛化能力、如何有效进行多模态融合等核心问题的理解还不够深入，这限制了我们对模型的进一步改进。

在注意力机制解释方面，虽然VisionFM采用了先进的注意力机制，但我们对其内部工作原理的解释还不够充分。我们难以准确解释模型为何关注某些特定区域，以及不同模态间的注意力权重如何影响最终决策。这种解释性不足影响了临床医师对模型的信任。

在模型可解释性研究方面，医学AI系统的可解释性对临床应用至关重要。虽然VisionFM在论文中报告了一定的可解释性，但我们在这方面的工作还比较初步，需要进一步开发更有效的可解释性分析方法。

#### 3.4 性能瓶颈分析

当前模型性能不佳的具体原因包括多个方面。在超参数调优方面，由于计算资源限制，我们无法进行充分的超参数搜索，导致当前的超参数设置可能不是最优的。特别是学习率、批处理大小、正则化系数等关键超参数需要进一步优化。

在预训练权重适配方面，我们使用的预训练权重与当前任务的数据分布存在差异，导致模型需要更长时间的适应。此外，预训练和微调阶段的数据预处理方式不一致也可能影响性能。

在训练数据规模方面，与VisionFM原始论文使用的340万张影像相比，我们的训练数据规模明显不足，这限制了模型学习复杂模式的能力。

在模型架构适配方面，我们直接采用了VisionFM的原始架构，没有根据具体任务特点进行针对性调整，可能导致模型架构与任务需求不完全匹配。

在评估指标局限性方面，我们主要采用了传统的分类和分割评估指标，这些指标可能无法全面反映模型在临床应用中的实际价值。需要开发更加贴近临床需求的评估体系。

## 第二部分：项目后期工作计划

### 1. 技术优化路线

#### 1.1 模型改进策略

在数据增强方案优化方面，我们将开发更加医学合理的数据增强策略，包括模态特定的增强方法和自适应增强强度调整。对于眼底摄影，我们将重点开发色彩空间变换和对比度增强方法；对于OCT图像，我们将开发基于物理模型的噪声注入和运动模糊模拟；对于FFA图像，我们将开发时序一致的数据增强方法。此外，我们还将探索生成式数据增强技术，如GAN和扩散模型，以生成高质量的眼科影像合成数据。

在少样本学习性能优化方面，基于VisionFM的少样本学习能力，我们将研究样本数量与模型性能的关系，其数学表达为：

$$\text{Performance}(k) = \alpha - \beta \cdot e^{-\gamma k}$$

其中$k$表示样本数量（$k=1,5,10$分别对应one-shot、five-shot和ten-shot），$\alpha$是性能上限，$\beta$和$\gamma$是控制学习曲线形状的参数。根据VisionFM论文，随着样本数量从1增加到10，AUC从0.993提升到1.00，符合这种指数增长模式。这个公式为我们优化少样本学习策略提供了理论依据。

在迁移学习技术应用方面，我们将深入研究迁移学习在眼科影像分析中的应用，包括域适应、少样本学习和零样本学习技术。具体而言，我们将探索如何将VisionFM在大规模数据上学到的知识有效迁移到小规模特定任务中，开发更加高效的微调策略，如适配器微调、提示学习等。我们还将研究跨模态迁移学习，利用一种模态的知识来增强另一种模态的学习。

在损失函数优化方面，我们将针对眼科影像分析的特点设计更加有效的损失函数。对于分类任务，我们将探索结合类别平衡和难例挖掘的损失函数；对于分割任务，我们将研究结合边界感知和区域一致性的损失函数；对于多模态任务，我们将设计模态特定和模态共享的复合损失函数。此外，我们还将探索自监督学习和对比学习损失，以提高模型的表示学习能力。

#### 1.2 训练流程优化

在学习率调度方面，我们将实施更加精细的学习率调度策略，包括预热阶段、衰减阶段和微调阶段的不同调度方案。我们将探索基于验证集性能的自适应学习率调整方法，以及针对不同模型层的差异化学习率设置。

在早停策略方面，我们将开发更加智能的早停策略，不仅基于验证集性能，还考虑训练稳定性和计算资源利用率。我们将探索基于多个指标的综合早停判断标准，以及基于模型性能变化趋势的预测性早停方法。

在模型集成方面，我们将研究模型集成技术，包括同质模型集成和异质模型集成。具体而言，我们将探索基于不同初始化、不同数据子集训练的多个VisionFM模型的集成，以及VisionFM与其他类型模型（如CNN、传统机器学习模型）的集成。我们还将研究动态集成方法，根据输入样本的特点自适应选择和组合不同的模型。

#### 1.3 性能提升目标

我们设定了以下具体的性能提升目标：

1. 多模态分类任务：将准确率从当前的58.3%提升至75%以上，AUC值从0.632提升至0.80以上；
2. 单模态分割任务：将Dice系数从0.676提升至0.82以上，IoU值从0.602提升至0.75以上；
3. 模型推理速度：在保持性能不下降的前提下，将单张图像推理时间减少30%以上；
4. 模型泛化能力：在跨数据集测试中，性能下降不超过5%。

### 2. 软件开发计划

#### 2.1 系统架构设计

我们将采用前后端分离的架构设计，前端使用React框架开发用户界面，后端使用Python Flask框架提供API服务。系统将采用模块化设计，主要包括数据管理模块、模型推理模块、结果可视化模块和用户管理模块。API接口将遵循RESTful设计原则，使用JSON格式进行数据交换，确保系统的可扩展性和可维护性。

#### 2.2 用户界面设计

用户界面将遵循医学专业人员的工作习惯，采用简洁直观的设计风格。主界面将包括图像上传区域、模型选择区域、参数设置区域和结果展示区域。我们将实现多种视图模式，包括单图查看、多图对比和三维重建视图。对于分析结果，我们将提供多种可视化方式，包括热力图、分割叠加图和统计图表，并支持生成结构化的诊断报告。

#### 2.3 部署方案

我们将提供多种部署方案以满足不同用户的需求。在Docker容器化方面，我们将提供完整的Docker镜像，包含所有依赖库和预训练模型，用户可以通过简单的命令启动整个系统。

在云端部署方面，我们将开发云端版本，支持多用户并发访问，并提供API接口供第三方系统集成。云端版本将采用自动扩缩容策略，确保服务稳定性。

在本地安装包方面，我们将提供Windows和Linux平台的本地安装包，支持离线使用，满足数据隐私要求高的场景。

### 3. 时间节点规划

以下是项目的详细时间规划：

| 阶段 | 任务 | 起止时间 | 里程碑 |
|------|------|----------|---------|
| 第一阶段 | 模型优化与训练 | 第1-6周 | 模型性能达到预设目标 |
| 第二阶段 | 系统架构设计与开发 | 第7-10周 | 完成系统核心功能开发 |
| 第三阶段 | 用户界面设计与实现 | 第11-13周 | 完成用户界面开发 |
| 第四阶段 | 系统集成与测试 | 第14-16周 | 完成系统集成测试 |
| 第五阶段 | 部署方案实施 | 第17-18周 | 完成多种部署方案 |
| 第六阶段 | 文档编写与项目验收 | 第19-20周 | 完成项目文档和验收 |

关键里程碑包括：第6周的模型性能达标、第13周的软件功能完成、第16周的系统集成完成和第20周的项目最终验收。

### 4. 风险评估与应对

#### 4.1 技术风险与应对

在模型性能不达标风险方面，如果模型优化后仍无法达到预设性能目标，我们将考虑以下备选方案：增加训练数据规模、采用更强大的模型架构、或者调整性能目标至合理水平。

在计算资源不足风险方面，如果计算资源不足以支持大规模模型训练，我们将寻求云计算资源支持，或者采用模型压缩和知识蒸馏技术减少计算需求。

#### 4.2 进度风险与应对

在开发进度延迟风险方面，如果开发进度落后于计划，我们将优先保证核心功能的实现，推迟非关键功能的开发，并考虑增加开发人员或延长项目周期。

在集成测试问题风险方面，如果系统集成测试发现重大问题，我们将预留足够的调试时间，并制定详细的回滚计划，确保项目能够按时交付。

## 第三部分：项目进展情况及取得成果

### 1. 项目进展情况及取得成果（按照项目研究工作计划逐一对照填写）

| 主要研究阶段（起止时间） | 研究内容 | 完成情况 |
|--------------------------|----------|----------|
| **第一阶段**<br>第1-6周<br>（2025年6月-7月） | VisionFM模型研读、深度学习环境搭建、数据预处理流程实现、模型训练与优化 | 已完成<br>• 掌握VisionFM核心技术原理<br>• 搭建PyTorch深度学习环境<br>• 实现多模态数据预处理流程<br>• 完成模型训练，多模态分类准确率58.3% |
| **第二阶段**<br>第7-10周<br>（2025年8月-9月） | 系统架构设计、模块化设计、API接口设计、核心功能开发 | 已完成<br>• 完成前后端分离架构设计<br>• 实现模块化系统设计<br>• 建立RESTful API接口<br>• 完成核心功能开发 |
| **第三阶段**<br>第11-13周<br>（2025年10月） | 用户界面设计、功能区域实现、视图模式开发、可视化实现 | 已完成<br>• 完成用户界面详细设计<br>• 实现主界面各功能区域<br>• 开发多种视图和可视化方式<br>• 建立结构化诊断报告机制 |
| **第四阶段**<br>第14-16周<br>（2025年11月） | 系统集成与测试、性能优化、稳定性测试、部署方案准备 | 进行中<br>• 完成模块初步集成测试<br>• 正进行系统性能优化<br>• 准备部署方案实现<br>• 解决系统集成相关问题 |

### 2. 项目研究成果（已取得的成果）

| 序号 | 项目成果名称 | 成果形式 |
|------|--------------|----------|
| 1 | VisionFM模型深度学习环境搭建 | 代码实现 |
| 2 | 多模态眼科影像数据预处理流程 | 代码实现 |
| 3 | 基于VisionFM的多模态分类模型 | 训练模型 |
| 4 | 系统性生物标志物预测算法实现 | 代码实现 |
| 5 | 单模态分割任务模型训练 | 训练模型 |
| 6 | 多模态注意力机制实验验证 | 实验数据 |
| 7 | 合成数据增强策略应用测试 | 实验数据 |
| 8 | 基线模型对比实验数据集 | 实验数据 |
| 9 | 模型性能评估指标数据 | 实验数据 |
| 10 | 自适应数据增强算法代码 | 代码实现 |
| 11 | 医学影像质量检测算法原型 | 代码实现 |
| 12 | 项目实验记录和技术笔记 | 技术文档 |
| 13 | 模型训练参数配置文件 | 配置文件 |
| 14 | 实验结果分析数据 | 数据集 |
